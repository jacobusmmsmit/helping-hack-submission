---
title: "Machine Learning with R"
output: html_notebook
---

## Setup

```{r package imports, message=FALSE}
library(dplyr)  # data manipulation
library(ggplot2)  # data visualisation
library(readr)  # data import
library(stringr)  # text processing
library(tidyr)  # data transformation
library(glmnet) 
library(tidymodels)
library(glmnetUtils)
```

```{r theming}
theme_set(theme_minimal())
```

```{r parameters}
BASE_URL <- paste0('https://raw.githubusercontent.com/warwickdatascience/',
                   'helping-hack-heart-of-england/main/resources/')
```

## Exploratory Analysis

Data available from the [hackathon website](https://warwickdatascience.github.io/helping-hack-heart-of-england/).

```{r data import, message=FALSE}
imd <- read_csv(paste0(BASE_URL, 'imd.csv'))
ref <- read_csv(paste0(BASE_URL, 'ref.csv'))
fra <- read_csv("data/lad_fra_lut.csv")
pfa <- read_csv("data/lad_pfa_lut.csv")
cty <- read_csv("data/lad_cty_lut.csv")
ca <- read_csv("data/lad_ca_lut.csv")


```

```{r sample datasets}
sample_n(imd, 10)
sample_n(ref, 10)
```

```{r change in imd}
imd %>%
  filter(!is.na(imd_2019)) %>%
  mutate(imd_change = imd_2019 - imd_2015) %>%
  ggplot(aes(x = imd_change)) +
    geom_histogram(bins = 25, col = 'black', fill = 'lightblue') +
    labs(x = "Change in IMD", y = "Count")
```

```{r data aggregation}
ref_agg <- ref %>%
  group_by(lad_code, lad_name, class, category) %>%
  # Note: 2017 Devon & Cornwall Police and Crime data is missing
  summarise(expenditure = mean(expenditure, na.rm = TRUE), .groups = 'drop')

sample_n(ref_agg, 10)
```

A massive flaw is already obvious: by not including county/London boroughs/other authorities, we are not accurately reflecting spending. We will not address this issue here as this is one way you can approve your leaderboard score.

```{r expenditure by category, fig.asp=2}
ref_agg %>%
  filter(expenditure > 0) %>%
  ggplot(aes(x = log(expenditure))) +
    geom_histogram(bins = 25, col = 'black', fill = 'lightblue') +
    labs(x = "Expenditure", y = "Count") +
    facet_wrap(~ category, ncol = 2)
```

```{r expenditure by category and class, fig.asp=0.5}
ref_agg %>%
  mutate(expenditure_sign = case_when(
    near(expenditure, 0) ~ 'Zero',
    expenditure < 0 ~ 'Negative',
    expenditure > 0 ~ 'Postive'
  ), class_type = case_when(
    class %in% c('L', 'UA', 'SD') ~ 'Individual',
    class %in% c('MD', 'SC') ~ 'Combined',
    TRUE ~ 'Other'
  )) %>%
  ggplot(aes(x = category, fill = expenditure_sign)) +
    geom_bar(aes()) +
    labs(x = "Expenditure Category", y = "Proportion", fill = "Expenditure Sign") +
    facet_wrap(~ class_type, scales = 'free_x') +
    coord_flip() +
    theme(axis.text.x = element_blank())
```

```{r correlations, fig.asp=2}
imd %>%
  filter(!is.na(imd_2019)) %>%
  mutate(imd_change = imd_2019 - imd_2015) %>%
  dplyr::select(lad_code, imd_change) %>%
  inner_join(dplyr::select(ref_agg, lad_code, category, expenditure) %>%
               filter(expenditure > 0),
             by = 'lad_code') %>%
  ggplot(aes(x = log(expenditure), y = imd_change)) +
    geom_point() +
    geom_smooth(method = 'lm', formula = y ~ x) +
    facet_wrap(~ category, scales = 'free', ncol = 2) +
    labs(x = "Expenditure", y = "Change in IMD")
```

## Modelling

```{r transform data}
ref_wide <- ref_agg %>%
  mutate(category = str_remove_all(
    str_replace_all(category, ' ', '_'), '[^\\w ]+'
  )) %>%
  spread(key = category, value = expenditure)

sample_n(ref_wide, 10)
```

```{r combine datasets}
combi <- imd %>%
  dplyr::select(lad_code, imd_2015, imd_2019) %>%
  left_join(dplyr::select(ref_wide, -c(lad_name, class)), by = 'lad_code')
```

```{r build null model}
# Null model on leaderboard
null <- lm(imd_2019 ~ offset(imd_2015),
          data = filter(combi, !is.na(imd_2019)))
```

```{r build model}
# Baseline model on leaderboard
mod <- lm(formula(paste0('imd_2019 ~ offset(imd_2015) + ',
                         paste(colnames(combi)[-(1:5)], collapse = ' + '))),
          data = filter(combi, !is.na(imd_2019)))
```

```{r build model with significant predictors}

mod3 <- lm(formula(paste0('imd_2019 ~ offset(imd_2015) + ',
                            paste(colnames(combi)[-c(1,2,3,4,5,6,8,9,10,14)], collapse = ' + '))),
            data = filter(combi, !is.na(imd_2019)))
```

## First try to include lookup tables

```{r -- not used how many small entit belong to a bigger fra entity}
num_fra <- fra %>%
    group_by(FRACD, YEAR) %>%
    count(LADCD) %>%
    dplyr::select(FRACD, YEAR, n) %>%
    unique()

```

```{r -not used how many small entit belong to a bigger pfa entity}
num_pfa <- pfa %>% dplyr::select(LADCD, PFACD) %>% 
    group_by(PFACD) %>%
    count(LADCD) %>%
    dplyr::select(PFACD, n) %>%
    unique()

```


```{r}
#joining combi with fire data
#1. join combi with bigger districts
bigset_fra <- fra %>%
    left_join(ref, by = c("FRACD" = "lad_code")) %>%
    filter(!is.na(lad_name))  %>%
    filter(year == YEAR)  %>%
    mutate(lad_code = LADCD) %>%
    dplyr::select(-YEAR, -FRACD, -LADCD)

bigset_pfa <- pfa %>%
    left_join(ref, by = c("PFACD" = "lad_code")) %>%
    filter(!is.na(lad_name)) %>%
    filter(year == YEAR) %>%
    mutate(lad_code = LADCD) %>%
    dplyr::select(-YEAR, -PFACD, -LADCD)

bigset_cty <- cty %>%
    left_join(ref, by = c("CTYCD" = "lad_code")) %>%
    filter(!is.na(lad_name)) %>%
    filter(year == YEAR) %>%
    mutate(lad_code = LADCD) %>%
    dplyr::select(-YEAR, -CTYCD, -LADCD)

bigset_ca <- ca %>%
    left_join(ref, by = c("CAUTHCD" = "lad_code")) %>%
    filter(!is.na(lad_name)) %>%
    filter(year == YEAR) %>%
    mutate(lad_code = LADCD) %>%
    dplyr::select(-YEAR, -CAUTHCD, -LADCD)
    
new_ref <- bind_rows(bigset_fra, ref, bigset_pfa, bigset_ca)
```



```{r do what Tim did before}
new_ref_agg <- new_ref %>%
  group_by(lad_code, lad_name, class, category) %>%
  # Note: 2017 Devon & Cornwall Police and Crime data is missing
  summarise(expenditure = mean(expenditure, na.rm = TRUE), .groups = 'drop')

new_ref_wide <- new_ref_agg %>%
  mutate(category = str_remove_all(
    str_replace_all(category, ' ', '_'), '[^\\w ]+'
  )) %>%
  spread(key = category, value = expenditure) %>%
  dplyr::select(-lad_name, -class) %>%
  group_by(lad_code) %>%
  summarize_all(sum)

new_combi <- imd %>%
  dplyr::select(lad_code, imd_2015, imd_2019) %>%
  left_join(new_ref_wide, by = 'lad_code')

```

```{r build model with significant predictors}

mod4 <- lm(formula(paste0('imd_2019 ~ offset(imd_2015) + ',
                            paste(colnames(new_combi)[c(7,11,12,14,16)], collapse = ' + '))),
            data = filter(new_combi, !is.na(imd_2019)))
```

```{r build model}
# Baseline model on leaderboard with new combi
mod5 <- lm(formula(paste0('imd_2019 ~ offset(imd_2015) + ',
                         paste(colnames(new_combi)[-c(1,3)], collapse = ' + '))),
          data = filter(combi, !is.na(imd_2019)))
```


```{r build model with significant predictors}

mod6a <- rlm(formula(paste0('imd_2019 ~ offset(imd_2015) + ',
                            paste(colnames(new_combi)[c(7,11,12,14,16)], collapse = ' + '))),
            data = filter(new_combi, !is.na(imd_2019)), psi = psi.huber)
mod6b <- rlm(formula(paste0('imd_2019 ~ offset(imd_2015) + ',
                            paste(colnames(new_combi)[c(7,11,12,14,16)], collapse = ' + '))),
            data = filter(new_combi, !is.na(imd_2019)), psi = psi.hampel)
mod6c <- rlm(formula(paste0('imd_2019 ~ offset(imd_2015) + ',
                            paste(colnames(new_combi)[c(7,11,12,14,16)], collapse = ' + '))),
            data = filter(new_combi, !is.na(imd_2019)), psi = psi.bisquare)

```

```{r}
rmse6a <- sqrt(sum((predict.lm(mod6a, newdata = filter(new_combi, !is.na(imd_2019))[-3])-filter(new_combi, !is.na(imd_2019))[3])^2)/311)
print(paste('rmse6a: ',rmse6a ))

# use this
rmse6b <- sqrt(sum((predict.lm(mod6b, newdata = filter(new_combi, !is.na(imd_2019))[-3])-filter(new_combi, !is.na(imd_2019))[3])^2)/311)
print(paste('rmse6b: ',rmse6b ))

mod6b_formula <- formula('imd_2019 ~ offset(imd_2015) + Cultural_and_Related_Services + 
    Highways_and_Transport + Housing_Services + Planning_and_Development_Services + 
    Public_Health')

rmse6c <- sqrt(sum((predict.lm(mod6c, newdata = filter(new_combi, !is.na(imd_2019))[-3])-filter(new_combi, !is.na(imd_2019))[3])^2)/311)
print(paste('rmse6c: ',rmse6c ))
```

```{r}
library(caret)
model_formula <- formula(paste0('imd_2019 ~ offset(imd_2015) + ',
                            paste(colnames(combi)[-c(1,2,3,4,5,6,8,9,10,14)], collapse = ' + ')))
model_caret <- train(
  mod6b_formula,
  data = filter(combi, !is.na(imd_2019)),          
  trControl = trainControl(method = "cv", number = 10), # folds
  method = "lm", # specifying regression model
  na.action = na.pass)

model_caret
```


```{r compare models}
anova(null, mod)
anova(mod, mod3)
anova(null,mod3)
anova(mod4, mod5)
```

## Model with glmnet ridge/lasso


```{r split data}
set.seed(42)
combi_filter <- new_combi %>% filter(!is.na(imd_2019))
combi_split <- initial_split(combi_filter, strata = imd_2019)
combi_train <- training(combi_split)
combi_test <- testing(combi_split)

combi_train.x <- as.matrix(combi_train[,-c(1,3)])
combi_train.y <- as.matrix(combi_train[,3])
combi_test.x <- as.matrix(combi_test[,-c(1,3)])
combi_test.y <- as.matrix(combi_test[,3])
 
```

```{r so far maybe our best submission}
mod01 <- cv.glmnet(combi_train.x,combi_train.y, type.measure="mse", 
  alpha=0.1, family="gaussian")
mod01_predicted <- predict(mod01, s=mod01$lambda.1se, newx = combi_test.x)
sqrt(mean((combi_test.y - mod01_predicted)^2))

```

```{r try cva.glmnet}
mod02 <- cva.glmnet(combi_train.x,combi_train.y, type.measure="mse", alpha = c(0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1),
  family="gaussian")
mod02_predicted <- predict(mod02, s=mod02$lambda.1se, newx = combi_test.x)
sqrt(mean((combi_test.y - mod02_predicted)^2))

```


```{r trying to get the formula}
mod01 <- cv.glmnet(combi_train.x,combi_train.y, type.measure="mse", 
  alpha=0.1, family="gaussian")

DF2formula(mod01)

mod01_predicted <- predict(mod01, s=mod01$lambda.1se, newx = combi_test.x)
sqrt(mean((combi_test.y - mod01_predicted)^2))

```


```{r cross validation for mod01 not working}
library(caret)

model_caret <- train(
  DF2formula(mod01),
  data = filter(new_combi, !is.na(imd_2019)),          
  trControl = trainControl(method = "cv", number = 10), # folds
  method = "glmnet", # specifying regression model
  na.action = na.pass)

model_caret
```

## Output

```{r make predictions}
pred <- predict(mod3, newdata = filter(combi, is.na(imd_2019)))
predexist <- predict(mod3, newdata = filter(combi, !is.na(imd_2019)))
```

```{r}
library(caret)
model_formula <- formula(paste0('imd_2019 ~ offset(imd_2015) + ',
                            paste(colnames(combi)[-c(1,2,3,4,5,6,8,9,10,14)], collapse = ' + ')))
model_caret <- train(
  model_formula,
  data = filter(combi, !is.na(imd_2019)),          
  trControl = trainControl(method = "cv", number = 10), # folds
  method = "lm", # specifying regression model
  na.action = na.pass)

model_caret
```

```{r}
library(caret)
model_formula <- formula(paste0('imd_2019 ~ offset(imd_2015) + ',
                            paste(colnames(new_combi)[c(7,11,12,14,16)], collapse = ' + ')))
model_caret <- train(
  model_formula,
  data = filter(new_combi, !is.na(imd_2019)),          
  trControl = trainControl(method = "cv", number = 10), # folds
  method = "lm", # specifying regression model
  na.action = na.pass)

model_caret
```
##Checking rmse

```{r}
rmse(filter(new_combi, !is.na(imd_2019))[3], predict.lm(mod5, newdata = filter(new_combi, !is.na(imd_2019))[-3]))



rmse4 <- sqrt(sum((predict.lm(mod4, newdata = filter(new_combi, !is.na(imd_2019))[-3])-filter(new_combi, !is.na(imd_2019))[3])^2)/311)
print(paste('rmse4: ',rmse4 ))
```

```{r}

rmse6 <- sqrt(sum((predict.lm(mod6, newdata = filter(new_combi, !is.na(imd_2019))[-3])-filter(new_combi, !is.na(imd_2019))[3])^2)/311)
print(paste('rmse6: ',rmse6 ))


```



```{r}
missing_data <- new_combi %>% filter(imd_2019 %>% is.na())

mod4 %>%
    predict.lm(newdata = missing_data) %>%
    mutate(missing_data, prediction = .) %>%
    dplyr::select(prediction, imd_2015, lad_code) %>%
    rename(imd_2019 = prediction) %>%
    left_join(imd %>% dplyr::select(lad_code, lad_name)) %>%
    dplyr::select(lad_code, lad_name, imd_2015, imd_2019) %>% 
    write_csv("predictions.csv")
```

```{r prediction with new_combi and mod01}
missing_data <- new_combi %>%
    filter(imd_2019 %>% is.na())
    

mod01 %>%
    predict(s=mod01$lambda.1se, newx = as.matrix(missing_data[,-c(1,3)])) %>%
    mutate(missing_data, prediction = .) %>%
    dplyr::select(prediction, imd_2015, lad_code) %>%
    rename(imd_2019 = prediction) %>%
    left_join(imd %>% dplyr::select(lad_code, lad_name)) %>%
    dplyr::select(lad_code, lad_name, imd_2015, imd_2019) %>% 
    write_csv("predictions2.csv")
```


```{r output predictions}
table <- (imd %>%
  filter(is.na(imd_2019)) %>%
  mutate(imd_2019 = pred) %>%
  write_csv('tutorial.csv'))
```

```{r chek rmse on existing imd_2019 data}
imd %>% 
    filter(!is.na(imd_2019)) %>% 
    mutate(new=predexist) %>% 
    rmse(imd_2019, predexist)
```
## Modelling - try with authority data

```{r addig not local level}
ref_wide <- ref_agg %>%
  mutate(category = str_remove_all(
    str_replace_all(category, ' ', '_'), '[^\\w ]+'
  )) %>%
  spread(key = category, value = expenditure)

sample_n(ref_wide, 10)
```


## Comments

Possible improvements:
- Use lookup tables to bring in all data sources
- Consider using multi-level modeling techniques
- Implement cross-validation to ensure generalisation
- Use regularisation to reduce generalisation gap
- Consider more complex models
- Model using a transformed expenditure
- Use time series modelling
